{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1:  Data Loading, GPU Dataframe Creation, and Data Manipulation\n",
    "Thanks to Anaconda for some material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will learn how to \n",
    "- Load data into a GPU Data Frame (GDF)\n",
    "- Learn about Dataframe level data functions\n",
    "- Learn about Seriers level data function \n",
    "- Manitulate data in a GDF to performance some basic ETL and statistical functions\n",
    "\n",
    "\n",
    "For this lab we will be looking at Netflow data.  The data consist of seven column which make it easy to visually inspect.  We will be manipulating the data in various way, many of which make not sense for doing cyber analysis.  \n",
    "\n",
    "\n",
    "This lab should take 30 to 50 minutes\n",
    "\n",
    "\n",
    "<br>\n",
    "As you progress in this lab look for instances of ***TASK:***, this will be where you will be asked to take an action to complete this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TASK:*** Execute the cell below to load the auto-time modules so that runtime execution of every cell is reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add autotime of each block\n",
    "#!pip install ipython-autotime\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "The first file we are going to load is netflow1.csv\n",
    "  \n",
    "Size = 965 MB<br>\n",
    "Records = 17,296,829"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load using the traditional Pandas interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /dli/data/kdd-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /dli/data/kdd-data/netflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the file name\n",
    "file_1 = '/dli/data/kdd-data/netflow/netflow1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the data - column names and data types \n",
    "cols = [\n",
    "    \"strdate\",\n",
    "    \"srcip\",\n",
    "    \"dstip\",\n",
    "    \"srcport\",\n",
    "    \"dstport\",\n",
    "    \"srcbytes\",\n",
    "    \"dstbytes\"   \n",
    "]\n",
    "\n",
    "\n",
    "dtypes = {    \n",
    "    \"strdate\"  : str,\n",
    "    \"srcip\"    : \"category\",\n",
    "    \"dstip\"    : \"category\",\n",
    "    \"srcport\"  : int,\n",
    "    \"dstport\"  : int,\n",
    "    \"srcbytes\" : int,\n",
    "    \"dstbytes\" : int\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data file contains a header line that needs to be skipped\n",
    "df = pd.read_csv(file_1,  names=cols, dtype=dtypes, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the loaded data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the first few rows of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "# Creating a GPU Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strings aren't supported yet\n",
    "gdf = pygdf.DataFrame.from_pandas(df.drop([\"strdate\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the data\n",
    "print(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Congrats you have created a GPU Data Frame!!!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transitioning GDF back to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just as easy\n",
    "df2 = gdf.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean-up: deleting a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up since we don't need df2\n",
    "del(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also drop the GPU dataframe since we will recreate it with some options\n",
    "del(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column-based funtions and Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the data\n",
    "df = pd.read_csv(file_1,  names=cols, dtype=dtypes, skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations on the current GDF version\n",
    "- Date are not fully supported   => scheduled for next version\n",
    "- String are not supported => also scheduled for next version\n",
    "- Categoricals are in early alpha where issues are expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could do df['strdate'] or ..\n",
    "df.strdate.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within Pandas - Convert the data from a string into parts\n",
    "df['Date']  = pd.to_datetime(df['strdate'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year']  = df.Date.dt.year\n",
    "df['Month'] = df.Date.dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Task:***  Convert day, hour, min, and second\n",
    "<details><summary>Click for Answer</summary>\n",
    "<code>\n",
    "df['Day']  = df.Date.dt.day\n",
    "df['Hour'] = df.Date.dt.hour\n",
    "df['Minute']  = df.Date.dt.minute\n",
    "df['Second'] = df.Date.dt.second\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns we no longer care about\n",
    "df = df.drop(['strdate','Date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create the GDF one more time\n",
    "gdf = pygdf.DataFrame.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it - the data is now loaded and available for accelerated Data Analysis on the GPU\n",
    "<br>\n",
    "<br>\n",
    "*Remember that **df = CPU** and **gdf = GPU** since we will switch back and forth for performance comparisons*\n",
    "<br>\n",
    "<br>\n",
    "***Data Loading Runtime*** = pd.read_csv + DataFrame.from_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Functionals and Transformations\n",
    "One of the basic GDF operations is column transform. To do that we use built-in arithmetic operations on each column\n",
    "\n",
    "***Note:*** The followiong function operate against a GDF Column - not against the full dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First some simple counting of the number of rows\n",
    "# NOTE: this counts the number of ***Non-NULL*** records are in the dataset?  \n",
    "gdf['srcport'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Task:***  How long does it take to do that simple counting on the CPU?\n",
    "<details><summary>Click for Answer</summary>\n",
    "<code>\n",
    "df['dstbytes'].count()\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### That is not enough data to truely push a GPU, let's load more\n",
    "file_2 = '/dli/data/kdd-data/netflow/netflow2.csv'\n",
    "#file_3 = '/dli/data/kdd-data/netflow/netflow3.csv'\n",
    "#file_4 = '/dli/data/kdd-data/netflow/netflow4.csv'\n",
    "\n",
    "df2 = pd.read_csv(file_2,  names=cols, dtype=dtypes, skiprows=1)\n",
    "#df3 = pd.read_csv(file_3,  names=cols, dtype=dtypes, skiprows=1)\n",
    "#df4 = pd.read_csv(file_4,  names=cols, dtype=dtypes, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractDateTime (d, column) :\n",
    "    d['Date']   = pd.to_datetime(d[column], format='%Y-%m-%d %H:%M:%S')\n",
    "    d['Year']   = d.Date.dt.year\n",
    "    d['Month']  = d.Date.dt.month    \n",
    "    d['Day']    = d.Date.dt.day\n",
    "    d['Hour']   = d.Date.dt.hour\n",
    "    d['Minute'] = d.Date.dt.minute\n",
    "    d['Second'] = d.Date.dt.second   \n",
    "    \n",
    "    d = d.drop([column,'Date'], axis=1)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = ExtractDateTime(df2, 'strdate')\n",
    "#df3 = ExtractDateTime(df3, 'strdate')\n",
    "#df4 = ExtractDateTime(df4, 'strdate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf2 = pygdf.DataFrame.from_pandas(df2)\n",
    "#gdf3 = pygdf.DataFrame.from_pandas(df3)\n",
    "#gdf4 = pygdf.DataFrame.from_pandas(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There's currently a bug in PyGDF in concatenating dataframes or Series containing \"category\" dtypes,\n",
    "#so lets drop those columns\n",
    "\n",
    "#Remove GDF columns is different than Pandas - can only do one column at a time for now\n",
    "gdf.drop_column('srcip')\n",
    "gdf.drop_column('dstip')\n",
    "\n",
    "gdf2.drop_column('srcip')\n",
    "gdf2.drop_column('dstip')\n",
    "\n",
    "#gdf3.drop_column('srcip')\n",
    "#gdf3.drop_column('dstip')\n",
    "\n",
    "#gdf4.drop_column('srcip')\n",
    "#gdf4.drop_column('dstip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the GDFs together\n",
    "#gdf = pygdf.concat([gdf, gdf2, gdf3, gdf4], ignore_index=True)\n",
    "gdf = pygdf.concat([gdf, gdf2], ignore_index=True)\n",
    "del(gdf2)\n",
    "#del(gdf3)\n",
    "#del(gdf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['srcport'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "was 17,296,828 now is 35,319,196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same on the CPU so that the two datasets are in sync\n",
    "#df = pd.concat([df, df2, df3, df4])\n",
    "df = pd.concat([df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and do a count\n",
    "df['srcport'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Type Conversion\n",
    "Let's continue cleaning up the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the max value for the source port?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['srcport'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the largest dstbyte size is less than an int32, let's convert the data type\n",
    "# This matches the Pandas syntax\n",
    "import numpy as np\n",
    "gdf['srcport'] = gdf['srcport'].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tasks:*** Find the max values for dstport, srcbytes, and dstbytes\n",
    "\n",
    "<details><summary>Click for Answer</summary>\n",
    "<code>\n",
    "gdf['dstport'].max()\n",
    "gdf['srcbytes'].max()\n",
    "gdf['dstbytes'].max()\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tasks:*** Convert dstport to int32\n",
    "\n",
    "<details><summary>Click for Answer</summary>\n",
    "<code>\n",
    "gdf['dstport'] = gdf['dstport'].astype(np.int32)\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Question:*** Why do we care about using smaller data types?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tasks:*** Looking at dstbytes:  what is min, max, mean, and standard deviation?\n",
    "\n",
    "<details><summary>Click for Answer</summary>\n",
    "<code>\n",
    "gdf['dstbytes'].min()\n",
    "gdf['dstbytes'].max()\n",
    "gdf['dstbytes'].mean()\n",
    "gdf['dstbytes'].std()\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Let's create a new column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations\n",
    "***Tasks:*** Create a new GDF column called **`totalbytes`** that is the sum of src and dst bytes\n",
    "\n",
    "<details><summary>Click for Answer</summary>\n",
    "<code>\n",
    "gdf['totalbytes'] = gdf['srcbytes'] + gdf['dstbytes']\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that a new column was created\n",
    "gdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the max byte size\n",
    "gdf['totalbytes'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try that same function on the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the same time on the CPU\n",
    "df['totalbytes'] = df['srcbytes'] + df['dstbytes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['totalbytes'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance gain is on a small dataset and a simple transformation.  As data size and analytic complexity increas so does the delta in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Operations\n",
    "The following function operate on a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "Selecting a subregion of data that matches an expresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get a count for reference of the total number of records\n",
    "gdf['srcport'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Extract a new Dataframe where the DST Port is not port 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_not_80 = gdf.query('dstport != 80')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Task:***  How many records are in the new set?\n",
    "<details><summary>Click for Answer</summary>\n",
    "<code>\n",
    "port_not_80['srcport'].count()\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to verify that this is a complete dataframe\n",
    "print(port_not_80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and let's do the same on the CPU\n",
    "cpu_port_not_80 = df.query('dstport != 80')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Task:***  delete those two dataset\n",
    "<details><summary>Click for Answer</summary>\n",
    "<code>\n",
    "del(port_not_80)\n",
    "del(cpu_port_not_80)\n",
    "</code>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data by the Source Port  \n",
    "# ***Note*** current version only support sorting on a single column\n",
    "by_srcport = gdf.sort_values(by='srcport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(by_srcport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping and Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column for count\n",
    "gdf['dummy'] = gdf['dstport']\n",
    "gdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs = OrderedDict()\n",
    "aggs['dummy'] = 'count'\n",
    "\n",
    "stats = gdf.groupby(['dstport']).agg(aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tasks:***  What is the count of SRC - DST Port groupings\n",
    "\n",
    "<details><summary>Click for answer</summary>\n",
    "<code>\n",
    "aggs = OrderedDict()\n",
    "aggs['dummy'] = 'count'\n",
    "\n",
    "stats = gdf.groupby(['srcport','dstport']).agg(aggs)\n",
    "</code>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "aggs = OrderedDict()\n",
    "aggs['dummy'] = 'count'\n",
    "\n",
    "stats = gdf.groupby(['srcport','dstport']).agg(aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TASK***\n",
    "- Normalize the total byte count to KB\n",
    "- Compute the Mean and Standard Deviations\n",
    "- Compute the Z-Score\n",
    "\n",
    "<details><summary>Click for answer - just one possibility</summary>\n",
    "<code>\n",
    "def Data_to_KB( raw_bytes ) :\n",
    "    return raw_bytes / 1024\n",
    "</code>\n",
    "<code>    \n",
    "gdf['KB'] = gdf['totalbytes'].applymap(Data_to_KB)\n",
    "</code>\n",
    "<code>\n",
    "mean = gdf['KB'].mean()\n",
    "</code>\n",
    "<code>\n",
    "std = gdf['KB'].std()\n",
    "</code>\n",
    "<code>\n",
    "print(\"Std == %f \\t Mean == %f\" % (std, mean))\n",
    "</code>\n",
    "<code>\n",
    "def z_score(kb) :\n",
    "    return ( (kb - mean) / std)\n",
    "</code>\n",
    "<code>\n",
    "gdf['Z'] = gdf['totalbytes'].applymap(Data_to_KB)\n",
    "</code>\n",
    "<code>\n",
    "gdf.dtypes\n",
    "</code>\n",
    "<code>\n",
    "print(gdf.head())\n",
    "</code>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
